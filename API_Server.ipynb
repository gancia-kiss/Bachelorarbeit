{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet #wornet loaded\n",
    "import re\n",
    "import json\n",
    "from flask import Flask,render_template, request, redirect, url_for\n",
    "from flask import jsonify, current_app\n",
    "from flask_cors import CORS\n",
    "\n",
    "#Methode definition\n",
    "def get_synsets(w):\n",
    "    syns = wordnet.synsets(w)\n",
    "    return syns\n",
    "\n",
    "def get_definitions(syns):\n",
    "    return syns.definition()\n",
    "\n",
    "def get_label(syns):\n",
    "    lemmas = syns.lemmas()\n",
    "    name = lemmas[0].name()\n",
    "    return name\n",
    "    #lemmas = syns.lemmas()\n",
    "   # name = lemmas[0].name()\n",
    "    #return syns.name()\n",
    "\n",
    "def get_class(syns):\n",
    "    return syns.pos()\n",
    "\n",
    "def get_resource(syns):\n",
    "    #return syns.lexname()\n",
    "    return syns.offset()  #id for a synset in wordnet db\n",
    "def get_source(syns):\n",
    "    #lemmas = syns.lemmas()\n",
    "    #name = lemmas[0].name()\n",
    "    #return name\n",
    "    return syns.name()\n",
    "    #return syns.lexname()\n",
    "    #return syns.offset()  #id for a synset in wordnet db\n",
    "\n",
    "def get_offset(w,text):\n",
    "    offset = text.index(w)\n",
    "    return offset\n",
    "\n",
    "def stop_words_filtering(text):\n",
    "    reg_exp = r\"[a-zA-Z0-9]+\"\n",
    " \n",
    "    stop_words = set(stopwords.words('english')) #stopwords just for englisch text\n",
    "    word_tokens= []\n",
    "    b = []\n",
    "    a = re.compile(reg_exp)\n",
    "#example = \"Pet food for shoes and fabric\"    \n",
    "        \n",
    "    b = b + a.findall(text)     \n",
    "    filtered_sentence =  [w for w in b if not w in stop_words] \n",
    "    filtered_sentence = [] \n",
    "    for w in b: #just filtern stopword in a text\n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)           \n",
    "    return filtered_sentence \n",
    "\n",
    "#Nested dictionary\n",
    "#def add_elementToRessourcedict(word, ressourcedict):\n",
    "def build_ressources_candidates(word,syns,offset):\n",
    "    resourcedict = {}\n",
    "    resourcedict[\"description\"] = get_definitions(syns)\n",
    "    resourcedict[\"label\"]       = get_label(syns)\n",
    "    resourcedict[\"offset\"]      = offset\n",
    "    resourcedict[\"resource\"]    = get_resource(syns)\n",
    "    resourcedict[\"source\"]      = get_source(syns)\n",
    "    resourcedict[\"text\"]        = word\n",
    "    resourcedict[\"pos\"]         = get_class(syns) #pos(part of speech oder word class)\n",
    "    return resourcedict\n",
    "     #resourcedict[\"synset_id\"]   = i\n",
    "    \n",
    "    \n",
    "    \n",
    "def build_resources(word,offset):\n",
    "    resources = []\n",
    "    synsets = get_synsets(word)\n",
    "    for syns in synsets:\n",
    "        resources.append(build_ressources_candidates(word,syns,offset))\n",
    "    return resources\n",
    "\n",
    "def build_annot_candidates(word,text):\n",
    "        offset = get_offset(word,text)\n",
    "        candidate = {}\n",
    "        candidate[\"offset\"]                = offset\n",
    "        candidate[\"resource_candidates\"]  = build_resources(word,offset)\n",
    "        candidate[\"text\"]                  = word\n",
    "        return candidate\n",
    "def build_annot(text):\n",
    "   # Woerter = stop_words_filtering(text)\n",
    "    annotDict = {}\n",
    "    annot = []\n",
    "    annotDict[\"annotation_candidates\"]   = annot\n",
    "    annotDict[\"text\"]                    = text\n",
    "    Woerter = stop_words_filtering(text)\n",
    "    for w in Woerter:\n",
    "        annot.append(build_annot_candidates(w,text))\n",
    "    return annotDict\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_annot(\"pet for food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:4000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [28/Nov/2019 19:04:00] \"GET /annotApi/to%20find%20lost%20livestock HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2019 19:06:11] \"GET /annotApi/the%20device%20could%20be%20used%20in%20a%20detective%20manner%20that%20is%20to%20say%20that%20it%20could%20be%20useful%20to%20predicting%20behavioral%20patterns%20of%20say%20criminal%20offenders,%20students,%20to%20perform%20research%20perhaps%20by%20tracking%20the%20physical%20lives%20of%20athletes%20or%20top%20achieving%20businessman%20or%20for%20companies%20to%20isolate%20expected%20behaviors%20of%20their%20employees%20and%20how%20they%20anticipate%20employees%20to%20move%20during%20a%20work%20day%20to%20establish%20fair%20and%20true%20standards HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2019 19:08:47] \"GET /annotApi/device%20could%20be%20used HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2019 19:08:47] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [28/Nov/2019 19:19:50] \"GET /annotApi/%20how%20they%20anticipate%20employees%20to%20move%20during%20a%20work%20day%20to%20establish%20fair%20and%20true%20standards HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "@app.route('/')\n",
    "def index():\n",
    "  return 'Server Works done!'\n",
    "    \n",
    "@app.route('/annotApi/<string:text>')\n",
    "def annotsFunction2(text):\n",
    "    annotation = build_annot(text)\n",
    "    return json.dumps(annotation)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    with app.app_context():\n",
    "   # app.debug = True\n",
    "        from werkzeug.serving import run_simple\n",
    "        run_simple('localhost', 4000, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
