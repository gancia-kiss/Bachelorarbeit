{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize \n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet #wornet loaded\n",
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "#import re\n",
    "\n",
    "\n",
    "def get_hypernym(syns):\n",
    "    hypernymList = []\n",
    "    paths = wordnet.synset(syns).hypernym_paths() #all Hypernym extract\n",
    "    for weg in paths:\n",
    "        hypernymList = hypernymList + [synset.name() for synset in weg]\n",
    "   # print(hypernymList)\n",
    "    hypernymList = list(dict.fromkeys(hypernymList )) #remove duplicate\n",
    "    return hypernymList\n",
    "def get_directhypernym(syns):\n",
    "    hypernymList = [hyp.name() for hyp in  wordnet.synset(syns).hypernyms()]\n",
    "    return hypernymList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['container.n.01', 'vehicle.n.01']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_directhypernym(\"wheeled_vehicle.n.01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_synsetsList(ideen):\n",
    "    synsetsDict  = {}\n",
    "    for idee in ideen_list:  #jeder idee durchlaufen\n",
    "        annotiert = idee.get(\"annotations\")\n",
    "        if annotiert :\n",
    "            for candidate in idee['annotations']: #word in eine idee  \n",
    "                if candidate['validated'] == True: #wenn diese word annotiert ist\n",
    "                    for resources in candidate['resource_candidates']: #annotation candidates durchlaufen\n",
    "                        if resources[\"selected\"] == True: #wenn ein kandidates ausgewählt ist\n",
    "                            if not synsetsDict.get(resources[\"source\"]): #wenn diese synsets noch nicht existiert\n",
    "                                synsetsDict[resources[\"source\"]] = []  # fügt diese synsets in synsetList\n",
    "                                synsetsDict[resources[\"source\"]].append(idee['id']) #fügt die idee_id die diese synset beinhaltet\n",
    "                            else:\n",
    "                                synsetsDict[resources[\"source\"]].append(idee['id']) #idee_id einfügen           \n",
    "                    #print(synsets)\n",
    "                else:\n",
    "                    print(\"not choice\")\n",
    "        else:\n",
    "            print(\"candidate was not annotiert\")\n",
    "    return synsetsDict\n",
    "def get_hypernymDict(ideen_list,synsetsDict):\n",
    "    hypernymDict = {}\n",
    "    #for idee in ideen_list:  #jeder idee durchlaufen \n",
    "    for key in synsetsDict.keys(): #hypernym von jeder synsets builden\n",
    "            hypernymList = get_hypernym(key)\n",
    "            for hypernym in hypernymList:\n",
    "                if not hypernymDict.get(hypernym): #wenn das Hypernym noch nicht existiert\n",
    "                    hypernymDict[hypernym]= []\n",
    "                    hypernymDict[hypernym].extend(synsetsDict[key]) #alle idee_id in der zugehörigen hypernym einfügen\n",
    "                    #get_hypernym(key)\n",
    "                #break\n",
    "                else: #sonst fügt die idee id nur\n",
    "                    hypernymDict[hypernym].extend(synsetsDict[key])\n",
    "                hypernymDict[hypernym] = list(dict.fromkeys(hypernymDict[hypernym] )) #remove duplicate\n",
    "                    \n",
    "    return hypernymDict\n",
    "                \n",
    "    \n",
    "   # print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate was not annotiert\n",
      "candidate was not annotiert\n",
      "candidate was not annotiert\n",
      "candidate was not annotiert\n",
      "candidate was not annotiert\n",
      "candidate was not annotiert\n"
     ]
    }
   ],
   "source": [
    "# read file\n",
    "with open('export.json', 'r') as myfile:\n",
    "    data = myfile.read()\n",
    "\n",
    "# parse file\n",
    "ideen_list   = json.loads(data)\n",
    "synsetsList  = get_synsetsList(ideen_list)\n",
    "hypernymList = get_hypernymDict(ideen_list,synsetsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Compost yard debris and food waste \n",
      " use LED lightbulbs \n",
      "People can replant tress that were cut down either due to logging or damage from weather or accident. \n"
     ]
    }
   ],
   "source": [
    "#for key in hypernymList.keys():\n",
    "    #print(len(hypernymList[key]))\n",
    "for idee in ideen_list:\n",
    "    for id in hypernymList['physical_entity.n.01']:\n",
    "        if idee['id'] == id:\n",
    "            print(idee['content'])\n",
    "#print(hypernymList['entity.n.01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dendrogramm\n",
    "#class Node(list):\n",
    "  #  def __init__(self, parent=None):\n",
    " #       self.parent = parent\n",
    "    \n",
    " #   def append(self, node):\n",
    " #       if isinstance(node, Node):\n",
    "  #          if node.parent == None:\n",
    " #               node.parent = self\n",
    "  #          list.append(self, node)\n",
    "\n",
    "\n",
    "#c1 = Node()\n",
    "#c2 = Node()\n",
    "#root.append(c1)\n",
    "#root.append(c2)\n",
    "\n",
    "#c2.append( Node() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.figure_factory import create_dendrogram\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from . import hierarchy\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "#from plotly.figure_factory import create_dendrogram\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import scipy.spatial as scs\n",
    "#\n",
    "#from scipy import hierarchy\n",
    "    \n",
    "#Index = ['A','B','C','D','E','F','G','H','I','J']\n",
    "#df    = pd.DataFrame(abs(np.random.randn(10, 10)), index=Index)\n",
    "#fig   = create_dendrogram(df, labels=Index)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree import Node, RenderTree\n",
    "from anytree.exporter import DotExporter\n",
    "# graphviz needs to be installed for the next line!\n",
    "#DotExporter(udo).to_picture(\"udo.png\")\n",
    "def get_key(key,dictionaryTree):\n",
    "    found = []\n",
    "    for a in (i for i in dictionaryTree.values()):\n",
    "    #for key in dictionaryTree.keys():\n",
    "        if key in a:\n",
    "            #print(key,a)\n",
    "            found = [j for j, value in d.items() if value == a]\n",
    "            #print(list(d.keys())[list(d.values()).index(key)])\n",
    "            #print(found)\n",
    "            #for i in found:\n",
    "             #   print (i)\n",
    "    return found\n",
    "def build_dictionary(dictionaryTree):\n",
    "    for element in dictionaryTree.copy():\n",
    "        #print(element)\n",
    "        if element == \"entity.n.01\":\n",
    "            pass\n",
    "        else:\n",
    "            hypernymList = get_directhypernym(element)\n",
    "            if not hypernymList:\n",
    "                dictionaryTree[\"entity.n.01\"].append(element)\n",
    "            else:\n",
    "                for hypernym in hypernymList:\n",
    "                   # found = get_key(hypernym)\n",
    "                    if hypernym in dictionaryTree.keys():\n",
    "                        dictionaryTree[hypernym].append(element)\n",
    "                    else:\n",
    "                        dictionaryTree[hypernym] = []\n",
    "                        dictionaryTree[hypernym].append(element)\n",
    "        #else:\n",
    "           # hypernym.child = b         \n",
    "        #dictionaryTree[hypernym] = []\n",
    "        #dictionaryTree[hypernym].append(syns)\n",
    "       # hypernym = Node(hypernym,child = syns)\n",
    "    # if element in testlist:\n",
    "    #print testlist.index(element)\n",
    "   # b = syns \n",
    "    #b = Node(syns)\n",
    "     #hypernym.child = b\n",
    "       # elif hypernym in (dictionaryTree[key] for key in dictionaryTree.key()):\n",
    "        #elif not found:\n",
    "    return dictionaryTree\n",
    "    \n",
    "def analyse(synsetsDict,dictionaryTree):\n",
    "    #dictionaryTree[\"entity.n.01\"] = []\n",
    "    for syns in synsetsDict.keys(): #hypernym von jeder synsets builden\n",
    "        if syns == \"entity.n.01\":\n",
    "            dictionaryTree[\"entity.n.01\"] = []\n",
    "        else:\n",
    "            hypernymList = get_directhypernym(syns)\n",
    "            dictionaryTree[\"entity.n.01\"] = []\n",
    "            for hypernym in hypernymList:\n",
    "                dictionaryTree[hypernym] = []\n",
    "                dictionaryTree[hypernym].append(syns)       \n",
    "    while len(dictionaryTree[\"entity.n.01\"]) != len(synsetsDict.keys()):\n",
    "        build_dictionary(dictionaryTree)\n",
    "        print(dictionaryTree)\n",
    "    return dictionaryTree\n",
    "        #if (len(dictionaryTree[\"entity.n.01\"]) != len(synsetsDict.keys())):\n",
    "             #hypernym = Node(hypernym,child = syns)\n",
    "        #treeset(syns,dictionaryTree)\n",
    "    #for key in dictionaryTree.keys():\n",
    "           # a = key+\".png\"\n",
    "           # DotExporter(b).to_picture(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "if __name__ == '__main__':\n",
    "    dictionaryTree = {}\n",
    "    with open('export.json', 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "# parse file\n",
    "    ideen_list   = json.loads(data)\n",
    "    synsetsList  = get_synsetsList(ideen_list)\n",
    "    #print(synsetsList.keys())\n",
    "    analyse(synsetsList,dictionaryTree)\n",
    "#hypernymList = get_hypernymDict(ideen_list,synsetsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
