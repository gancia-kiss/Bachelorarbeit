{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize \n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import wordnet #wornet loaded\n",
    "import re\n",
    "import json\n",
    "from flask import Flask,render_template, request, redirect, url_for\n",
    "from flask import jsonify, current_app\n",
    "from flask_cors import CORS\n",
    "\n",
    "#Methode definition\n",
    "# https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string\n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start\n",
    "\n",
    "def get_synsets(w):\n",
    "    syns = wordnet.synsets(w)\n",
    "    return syns\n",
    "\n",
    "def get_definitions(syns):\n",
    "    return syns.definition()\n",
    "\n",
    "def get_label(syns):\n",
    "    lemmas = syns.lemmas()\n",
    "    name = lemmas[0].name()\n",
    "    return name\n",
    "\n",
    "def get_class(syns):\n",
    "    return syns.pos()\n",
    "\n",
    "def get_resource(syns):\n",
    "    return syns.offset()  #id for a synset in wordnet db\n",
    "\n",
    "def get_source(syns):\n",
    "    return syns.name()\n",
    "\n",
    "# what if the text is used multiple times?\n",
    "def get_offset(w,text,nth):\n",
    "    offset = find_nth(text, w, nth)\n",
    "    return offset\n",
    "\n",
    "def stop_words_filtering(text):\n",
    "    reg_exp = r\"[a-zA-Z0-9_-]+\"  #Reguläre Ausdruck, der alle erlaubten Sylabeln enthält. Von \"a\" bis \"z\"\n",
    "                            #von \"A\" bis \"Z\"   \n",
    "    stop_words  = set(stopwords.words('english')) #stopwörter für englisches Text\n",
    "    word_tokens = []\n",
    "    a = re.compile(reg_exp)\n",
    "    word_tokens = word_tokens + a.findall(text) #löscht die Satzzeichnen im Text\n",
    "    filtered_sentence = filtered_sentence2 =  [w for w in word_tokens if not w in stop_words] #löscht die Stopp-Wörter im Text\n",
    "    return filtered_sentence \n",
    "\n",
    "\n",
    "#Nested dictionary\n",
    "def build_ressources_candidates(word,syns,offset):\n",
    "    resourcedict = {}\n",
    "    resourcedict[\"description\"] = get_definitions(syns)\n",
    "    resourcedict[\"label\"]       = get_label(syns)\n",
    "    resourcedict[\"offset\"]      = offset\n",
    "    resourcedict[\"resource\"]    = get_resource(syns)\n",
    "    resourcedict[\"source\"]      = get_source(syns)\n",
    "    resourcedict[\"text\"]        = word\n",
    "    resourcedict[\"pos\"]         = get_class(syns) #pos(part of speech oder word class)\n",
    "    return resourcedict   \n",
    "    \n",
    "def build_resources(word,offset):\n",
    "    resources = []\n",
    "    synsets = get_synsets(word)\n",
    "    if \"-\" in word:\n",
    "        tokens = word.split(\"-\")\n",
    "        for w in tokens:\n",
    "            synsets.extend(get_synsets(w))\n",
    "    elif \"_\" in word:\n",
    "        tokens = word.split(\"_\")\n",
    "        for w in tokens:\n",
    "            synsets.extend(get_synsets(w))    \n",
    "    for syns in synsets:\n",
    "        resources.append(build_ressources_candidates(word,syns,offset))\n",
    "    return resources\n",
    "\n",
    "def build_annot_candidates(word,text,current_word_occurence_count):\n",
    "        offset = get_offset(word,text,current_word_occurence_count)\n",
    "        candidate = {}\n",
    "        candidate[\"offset\"]                = offset\n",
    "        candidate[\"resource_candidates\"]  = build_resources(word,offset)\n",
    "        candidate[\"text\"]                  = word\n",
    "        return candidate\n",
    "    \n",
    "def build_annot(text):\n",
    "    annotDict = {}\n",
    "    annot = []\n",
    "    annotDict[\"annotation_candidates\"]   = annot\n",
    "    annotDict[\"text\"]                    = text\n",
    "    Woerter = stop_words_filtering(text)\n",
    "    wordCount = {} \n",
    "    for w in Woerter:\n",
    "        find = 0\n",
    "        if not bool(wordCount): #wenn dictionary leer ist\n",
    "            wordCount[w] = 0\n",
    "            wordCount[w] = wordCount[w] + 1\n",
    "            currentWordCount = wordCount[w]\n",
    "        else:\n",
    "            for key in wordCount.copy():  \n",
    "                if (key.find(w) != -1):\n",
    "                    wordCount[key] = wordCount[key] + 1\n",
    "                    currentWordCount = wordCount[key]\n",
    "                    find = 1\n",
    "                    break\n",
    "            if find != 1:\n",
    "                wordCount[w] = 0\n",
    "                wordCount[w] = wordCount[w] + 1\n",
    "                currentWordCount = wordCount[w]\n",
    "        annot.append(build_annot_candidates(w,text, currentWordCount))\n",
    "                    \n",
    "    return annotDict\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "@app.route('/')\n",
    "def index():\n",
    "  return 'Server Works done!'\n",
    "    \n",
    "@app.route('/annotApi/<path:text>')\n",
    "def annotsFunction2(text):\n",
    "    annotation = build_annot(text)\n",
    "    return json.dumps(annotation)\n",
    "\n",
    "@app.errorhandler(404)\n",
    "def not_found():\n",
    "    \"\"\"Page not found.\"\"\"\n",
    "    return make_response(render_template(\"404.html\"), 404)\n",
    "\n",
    "#https://hackersandslackers.com/flask-routes/\n",
    "\n",
    "@app.errorhandler(400)\n",
    "def bad_request():\n",
    "    \"\"\"Bad request.\"\"\"\n",
    "    return make_response(render_template(\"400.html\"), 400)\n",
    "\n",
    "\n",
    "@app.errorhandler(500)\n",
    "def server_error():\n",
    "    \"\"\"Internal server error.\"\"\"\n",
    "    return make_response(render_template(\"500.html\"), 500)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    with app.app_context():\n",
    "   # app.debug = True\n",
    "        from werkzeug.serving import run_simple\n",
    "        run_simple('localhost', 4000, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
