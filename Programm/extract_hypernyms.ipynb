{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliothek load\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from graphviz import Graph\n",
    "import pandas as pd\n",
    "from anytree import Node, RenderTree\n",
    "from anytree.exporter import DotExporter\n",
    "import sys\n",
    "\n",
    "\n",
    "#Basis Hypernym Funktion für die Extraktion des Hypernymes\n",
    "def get_hypernym(syns):\n",
    "    hypernymList = []\n",
    "    paths = wordnet.synset(syns).hypernym_paths() #all Hypernym extract\n",
    "    for weg in paths:\n",
    "        hypernymList = hypernymList + [synset.name() for synset in weg]\n",
    "    #print(paths)\n",
    "    hypernymList = list(dict.fromkeys(hypernymList )) #remove duplicate\n",
    "    return hypernymList\n",
    "def get_directhypernym(syns):\n",
    "    hypernymList = [hyp.name() for hyp in  wordnet.synset(syns).hypernyms()]\n",
    "    return hypernymList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hier werden alle benötigten Wörtebucher erstellt\n",
    "\n",
    "#Mapping des Ideen mit nummerId und Content\n",
    "def get_dictionaryIdee(ideen):\n",
    "    ideenDict = {}  # key = (nummerId,Id) Value = Content\n",
    "    nummer = 1\n",
    "    for idee in ideen:  #jeder idee durchlaufen\n",
    "        ideenDict[(nummer,idee[\"id\"])] = idee.get(\"content\")\n",
    "        nummer = nummer+1\n",
    "    return ideenDict\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#SynsetsDict mit der Ausgewählten Synsets bei der Annotation\n",
    "def get_synsetsList(ideen):\n",
    "    synsetsDict  = {} # key = Synset Value = [list von ID]\n",
    "    for idee in ideen:  #jeder idee durchlaufen\n",
    "        annotiert = idee.get(\"annotations\")\n",
    "        if annotiert :\n",
    "            for candidate in idee['annotations']: #word in eine idee  \n",
    "                if candidate['validated'] == True: #wenn diese word annotiert ist\n",
    "                    for resources in candidate['resource_candidates']: #annotation candidates durchlaufen\n",
    "                        if resources[\"selected\"] == True: #wenn ein kandidates ausgewählt ist\n",
    "                            if not synsetsDict.get(resources[\"source\"]): #wenn diese synsets noch nicht existiert\n",
    "                                synsetsDict[resources[\"source\"]] = []  # fügt diese synsets in synsetList\n",
    "                                synsetsDict[resources[\"source\"]].append(idee['id']) #fügt die idee_id die diese synset beinhaltet\n",
    "                            else:\n",
    "                                synsetsDict[resources[\"source\"]].append(idee['id']) #idee_id einfügen           \n",
    "                else:\n",
    "                    print(\"not choice\")\n",
    "        else:\n",
    "            print(\"candidate was not annotiert\")\n",
    "    return synsetsDict\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#Hypernym Wörterbuch mit der Hypernyme der behinhaltet Ideen ID \n",
    "def get_hypernymDict(synsetsDict):\n",
    "    hypernymDict = {} #Key = hypernym , Value = [ListId]\n",
    "    #for idee in ideen_list:  #jeder idee durchlaufen \n",
    "    for key in synsetsDict.keys(): #hypernym von jeder synsets builden\n",
    "            hypernymList = get_hypernym(key)\n",
    "            if hypernymList:\n",
    "                for hypernym in hypernymList:\n",
    "                    if not hypernymDict.get(hypernym): #wenn das Hypernym noch nicht existiert\n",
    "                            hypernymDict[hypernym]= []\n",
    "                            hypernymDict[hypernym].extend(synsetsDict[key]) #alle idee_id in der zugehörigen hypernym einfügen\n",
    "                 \n",
    "                    else: #sonst fügt die idee id nur\n",
    "                            hypernymDict[hypernym].extend(synsetsDict[key])\n",
    "                    hypernymDict[hypernym] = list(dict.fromkeys(hypernymDict[hypernym] )) #remove duplicate\n",
    "                    \n",
    "    return hypernymDict\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Hilfsfunktion für DictionaryTree Extrahiert nach einander des DirectHypernymen des vorhandenen Hypernymen(Synsets) \n",
    "def build_dictionary(dictionary_actual):\n",
    "    Anzahl = 0\n",
    "    for element in dictionary_actual.copy():\n",
    "        if element == \"entity.n.01\":\n",
    "            pass\n",
    "        else:\n",
    "            hypernymList = get_directhypernym(element)\n",
    "            if hypernymList == []: #wenn kein direct hypernym mehr vorhanden ist. bzw. ist schon entity\n",
    "                Anzahl= Anzahl + 1\n",
    "                #print(\"elem ist: \", element)\n",
    "                if \"entity.n.01\" in dictionary_actual:\n",
    "                    dictionary_actual[\"entity.n.01\"].append(element)\n",
    "                else:\n",
    "                    dictionary_actual[\"entity.n.01\"] = []\n",
    "                    dictionary_actual[\"entity.n.01\"].append(element)\n",
    "            else:\n",
    "                for hypernym in hypernymList:\n",
    "                    if hypernym in dictionary_actual:\n",
    "                        dictionary_actual[hypernym].append(element)\n",
    "                    else:\n",
    "                        dictionary_actual[hypernym] = []\n",
    "                        dictionary_actual[hypernym].append(element)\n",
    "    print (\"entity\", Anzahl)    \n",
    "    return dictionary_actual\n",
    "\n",
    "#dictionaryTree: Beziehungen zwischen alle Hypernymen\n",
    "def analyse(synsetsDict):\n",
    "    #f = open(filename,'w')\n",
    "    dictionaryTree = {} #schon bearbeiten knoten #key = hypernyme Value = [List von Hypernymen die als directHypernym der Key haben]\n",
    "    dictionary_actual = {} #contains new Hypernym which is not in dictionaryTree\n",
    "    #distance_matrix = \n",
    "    for syns in synsetsDict.keys(): #hypernym von jeder synsets builden\n",
    "        dictionary_actual[syns] = []\n",
    "        dictionaryTree[syns]    = []\n",
    "                \n",
    "    while(len(dictionary_actual) != 0):\n",
    "        dictionary_actual = build_dictionary(dictionary_actual)\n",
    "        for elem in dictionary_actual.copy():\n",
    "            if elem in dictionaryTree: #wenn diese elem schon vorhanden ist\n",
    "                dictionaryTree[elem].extend(dictionary_actual.pop(elem)) #fügt einfach die leaves hinzu und lösch diese aus dem actual schon bearbeiten\n",
    "                dictionaryTree[elem] = list(dict.fromkeys(dictionaryTree[elem])) #remove duplicate\n",
    "            else:\n",
    "                dictionaryTree[elem] = [] #wenn nicht erstellt einen neue Eltern knoten\n",
    "                dictionaryTree[elem].extend(dictionary_actual[elem])\n",
    "                #dictionaryTree[elem] = dictionary_actual[elem] #fügt die leaves davon            \n",
    "    return dictionaryTree\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#ideen_synsetsDict: Pro Ideen alle behinhaltetet Synsets\n",
    "def mapping_idee_to_synsets(ideen):\n",
    "    ideen_synsetsDict = {}  # key = (nummerId,Id) Value = [Listsynsets]\n",
    "    nummer = 1\n",
    "    for idee in ideen:  #jeder idee durchlaufen\n",
    "        ideen_synsetsDict[(nummer,idee[\"id\"])] = []\n",
    "        annotiert = idee.get(\"annotations\")\n",
    "        if annotiert :\n",
    "            for candidate in idee['annotations']: #word in eine idee  \n",
    "                if candidate['validated'] == True: #wenn diese word annotiert ist\n",
    "                    for resources in candidate['resource_candidates']: #annotation candidates durchlaufen\n",
    "                        if resources[\"selected\"] == True: #wenn ein kandidates ausgewählt ist\n",
    "                            ideen_synsetsDict[(nummer,idee[\"id\"])].append(resources[\"source\"])\n",
    "        nummer = nummer +1 \n",
    "    return ideen_synsetsDict\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#ideen_hypernymDict: Pro Idee alle behinhatetet Hypernymen\n",
    "def mapping_idee_to_hypernym(ideen_synsetsDict):\n",
    "    ideen_hypernymDict = {} # key = (nummerId,Id)  Value = [Listhypernymen]\n",
    "    for elem in ideen_synsetsDict:\n",
    "        ideen_hypernymDict[elem] = []\n",
    "        for synset in ideen_synsetsDict[elem]:\n",
    "            hypernymList = get_hypernym(synset)\n",
    "            ideen_hypernymDict[elem].extend(hypernymList)\n",
    "        ideen_hypernymDict[elem] = list(dict.fromkeys(ideen_hypernymDict[elem] )) #remove duplicate\n",
    "    return ideen_hypernymDict\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#occurence_synsetsDict: Anzahl an Occurence von einen Synset in der Datensatzt     \n",
    "def occurence_of_synset(ideen_synsetDict):\n",
    "    occurence_synsetsDict = {} #key = synset Value = occurence\n",
    "    for synslist in ideen_synsetDict.values():\n",
    "        for syns in synslist:\n",
    "            if not (syns in occurence_synsetsDict.keys()):\n",
    "                occurence_synsetsDict[syns] = 0\n",
    "            occurence_synsetsDict[syns] = occurence_synsetsDict[syns] + 1\n",
    "    return occurence_synsetsDict\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Jeder Ideen auf einen Konzept reduzieren Konzept die am wenigstens in der Datensatz vorkommen genau 1% \n",
    "#Beim mehrere Konzept pro Ideen mit der wiederholung Prozent gleich 1% wählen wir einfach der Erste\n",
    "def Prozent(tupel,i):\n",
    "    prozent = ((((tupel[-1][1])*i)//100)+1)\n",
    "    return prozent\n",
    "def ideen_synsetDict_clearly(ideen_synsetsDict, occurence_synsetsDict): #Mapping Ideen zu besten Synset\n",
    "    ideen_synsetdict_clearly = {}\n",
    "    tupel  = [(k, v) for k, v in occurence_synsetsDict.items()]\n",
    "    tupel.sort(key = sort_by_keys)\n",
    "    kleiner = [k for k,i in tupel if i<=Prozent(tupel,1)]\n",
    "    for i,j in ideen_synsetsDict.items():\n",
    "        synsets = [s for s in j if s in kleiner]\n",
    "        synsets = list(dict.fromkeys(synsets)) #duplicate löschen\n",
    "        ideen_synsetdict_clearly[i] = []\n",
    "        if len(synsets) >= 1 :   #ideen die Mehr als 1 besten synset hat einfach die erste auswählen.\n",
    "            ideen_synsetdict_clearly[i].append(synsets[0])\n",
    "        else: #ideen die kein Inhalt mehr haben(Grund alle Synsets existiert schon in einer andere Idee) \n",
    "            a = 2\n",
    "            while len(synsets) == 0: #Anzahl der wiederholung erhöhen und weiter suchen\n",
    "                kleiner2 = [k for k,i in tupel if i<=Prozent(tupel,a)]\n",
    "                synsets = [s for s in j if s in kleiner2]\n",
    "                synsets = list(dict.fromkeys(synsets)) #duplicate löschen\n",
    "                a=a+1\n",
    "            ideen_synsetdict_clearly[i].append(synsets[0])          \n",
    "    \n",
    "    return ideen_synsetdict_clearly #key = (nummerId,Id), Value = [ein Synset]\n",
    "\n",
    "def synsetDict_clearly(ideen_synsetdict_clearly, synsetsDict ): #new SynsetDict mit besten Synset\n",
    "    for synset in synsetsDict.copy():\n",
    "        find = False \n",
    "        for item in ideen_synsetdict_clearly.values():\n",
    "            if synset in item:\n",
    "                find = True\n",
    "        if find == False:\n",
    "            synsetsDict.pop(synset)\n",
    "    return synsetsDict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#darstellung des DictionaryTree in einen Baum Form\n",
    "def build_tree(dictionaryTree):\n",
    "    #anzahl = 0\n",
    "    parent = Graph('parent')\n",
    "    for elem in dictionaryTree:\n",
    "        for node in dictionaryTree[elem]:\n",
    "            parent.edge(elem,node,len='1.00')\n",
    "    leaves = Graph('child')\n",
    "    leaves.attr(rank='same')\n",
    "    for elem in dictionaryTree.keys():\n",
    "        if dictionaryTree[elem] == []:\n",
    "            #anzahl = anzahl + 1\n",
    "            leaves.node(elem)\n",
    "    #print(anzahl)\n",
    "    parent.subgraph(leaves)\n",
    "    parent.view()\n",
    "\n",
    "    \n",
    "def build_part_of_tree(Tree,knoten):\n",
    "    s = Graph(knoten)\n",
    "    for node in Tree[knoten]:\n",
    "        s.edge(knoten,node)\n",
    "    s.view()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balkendiagramm Darstellung des vorhandenen Dictionary\n",
    "\n",
    "def sort_by_keys(val):\n",
    "    return val[1]\n",
    "\n",
    "#https://matplotlib.org/examples/api/barchart_demo.html\n",
    "def autolabel(rects,ax):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%d' % int(height),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "\n",
    "\n",
    "#https://bodo-schoenfeld.de/jupyter-notebook-balkendiagramm-erstellen/\n",
    "def plot_balken_hypernym(hypernymdict,prozent,prozentr):\n",
    "    fig, ax = plt.subplots()\n",
    "    tupel2 = [(k, len(v)) for k, v in hypernymdict.items()]\n",
    "    tupel2.sort(key = sort_by_keys)\n",
    "    prozent2 = ((tupel2[-1][1] * prozent)/100)\n",
    "    prozent3 = ((tupel2[-1][1] * prozentr)/100)\n",
    "    kleiner = [k for k,i in tupel2 if i<=prozent2]\n",
    "    groesser = [k for k,i in tupel2 if i>=prozent3]\n",
    "    #print(\"Others: \", kleiner)\n",
    "    tupel = [(k,v) for k,v in tupel2 if k not in kleiner]\n",
    "    tupel = [(k,v) for k,v in tupel if k not in groesser]\n",
    "    \n",
    "    length2 = len(tupel) \n",
    "    #print(length2)\n",
    "    tupel.insert(0,(\"Others\",prozent2))\n",
    "    tupel.insert(length2+1,(\"Others2\",prozent3))\n",
    "    \n",
    "    hypernymlist = [i[0] for i in tupel]\n",
    "    anteile = [i[1] for i in tupel]\n",
    "    anteile.sort()\n",
    "    index = np.arange(len(hypernymlist))\n",
    "    bar_width = 0.5\n",
    "    bars = plt.bar(index, anteile,bar_width,color=\"green\")\n",
    "    plt.xticks(index, hypernymlist,fontsize=20)\n",
    "    plt.title(\"Anzahl von Ideen pro Hypernym\",fontsize=30)\n",
    "    plt.ylabel('Anzahl von Ideen',fontsize=30)\n",
    "    plt.xlabel(\"Hypernym\",fontsize=30)\n",
    "    length = anteile[-1] + 5\n",
    "    plt.ylim(0,length) #y-achse höhe\n",
    "    ax.set_xticks(range(len(hypernymlist)))\n",
    "    ax.set_xticklabels(hypernymlist, rotation='vertical')\n",
    "    fig_size = plt.gcf().get_size_inches() #Get current size\n",
    "    sizefactor = 3 #Set a zoom factor\n",
    "    autolabel(bars,ax)\n",
    "    plt.gcf().set_size_inches(sizefactor * fig_size) # Modify the current size by the factor\n",
    "    #plt.show()\n",
    "    plt.savefig('balken_hypernym.pdf')\n",
    "    \n",
    "def plot_hypernyme_fenster(hypernymdict,minimum,maximum): #gute Liste von Hypernyme Anzahl an ideen zwischen min-max\n",
    "    fig, ax = plt.subplots()\n",
    "    tupel2 = [(k, len(v)) for k, v in hypernymdict.items()]\n",
    "    tupel2.sort(key = sort_by_keys)\n",
    "    tupel = [(k,v) for k,v in tupel2 if minimum <= v <= maximum] #k= hyp und v = anzahl\n",
    "    Anzahlhypernyme = []\n",
    "    Abdeckung = []\n",
    "    Anzahlidee = []\n",
    "    minimum_h = minimum\n",
    "    while minimum_h <= maximum:\n",
    "        tupel3 = [(k,v) for k,v in tupel if minimum_h == v]\n",
    "        if len(tupel3)<=1:\n",
    "               # A = []\n",
    "                pass\n",
    "        else:\n",
    "            A = set(hypernymdict[tupel3[0][0]]).intersection(set(hypernymdict[tupel3[1][0]]))\n",
    "            if len(tupel3)>2:\n",
    "                for i in range (2,len(tupel3)):\n",
    "                    A = A.intersection(set(hypernymdict[tupel3[i][0]]))\n",
    "            if (len(A)>0):\n",
    "                Abdeckung.append(len(A))\n",
    "                Anzahlhypernyme.append(len(tupel3))\n",
    "                Anzahlidee.append(minimum_h)\n",
    "        minimum_h = minimum_h + 1\n",
    "   # print(Abdeckung)\n",
    "   # print(Anzahlhypernyme)\n",
    "   # print([i for i in range (minimum, maximum+1)])\n",
    "        \n",
    "    tabelle = pd.DataFrame({\n",
    "        'Anzahl an Ideen':pd.Categorical([i for i in Anzahlidee]),                                 \n",
    "        'Überschneidung' :pd.Categorical(Abdeckung),\n",
    "        'Anzahlhypernyme':pd.Categorical([i for i in Anzahlhypernyme])\n",
    "    })\n",
    "    tabelle.to_excel(\"HypernymFenster.xlsx\")\n",
    "    #print(tabelle)\n",
    "    #newtupel = \n",
    "    hypernymlist = [i[0] for i in tupel if i[1] in Anzahlidee]\n",
    "    anteile = [i[1] for i  in tupel if i[1] in Anzahlidee]\n",
    "    anteile.sort()\n",
    "    #print(anteile)\n",
    "    index = np.arange(len(hypernymlist))\n",
    "    bar_width = 0.5\n",
    "    bars = plt.bar(index, anteile,bar_width,color=\"green\")\n",
    "    plt.xticks(index, hypernymlist,fontsize=20)\n",
    "    plt.title(\"Hypernyme mit Anzahl an Ideen zwischen \" + str(minimum) + \" und \" + str(maximum) + \" inklusive\",fontsize=25)\n",
    "    plt.ylabel('Anzahl von Ideen',fontsize=30)\n",
    "    plt.xlabel(\"Hypernym\",fontsize=30)\n",
    "    length = anteile[-1] + 5\n",
    "    plt.ylim(0,length) #y-achse höhe\n",
    "    ax.set_xticks(range(len(hypernymlist)))\n",
    "    ax.set_xticklabels(hypernymlist, rotation='vertical')\n",
    "    fig_size = plt.gcf().get_size_inches() #Get current size\n",
    "    sizefactor = 3 #Set a zoom factor\n",
    "    autolabel(bars,ax)\n",
    "    plt.gcf().set_size_inches(sizefactor * fig_size) # Modify the current size by the factor\n",
    "    plt.show()\n",
    "    \n",
    "def plot_mapping_idee_Synstet(ideen_synsetDict,prozent):\n",
    "    fig, ax = plt.subplots()\n",
    "    tupel2 = [(k[0], len(v)) for k, v in ideen_synsetDict.items()]\n",
    "    tupel2.sort(key = sort_by_keys)\n",
    "    prozent2 = ((tupel2[-1][1] * prozent)/100)\n",
    "    kleiner = [k for k,i in tupel2 if i<=prozent2]\n",
    "    print(\"Others: \", kleiner)\n",
    "    tupel = [(k,v) for k,v in tupel2 if k not in kleiner]\n",
    "    tupel.insert(0,(\"Others\",prozent2))\n",
    "    ideen_id = [i[0] for i in tupel]\n",
    "    anteile  = [i[1] for i in tupel]\n",
    "    anteile.sort()\n",
    "    index = np.arange(len(ideen_id))\n",
    "    bars2 = plt.bar(index, anteile,color=\"green\")\n",
    "    plt.xticks(index, ideen_id,fontsize=20)\n",
    "    plt.title(\"Anzahl von Synset pro Idee\",fontsize=30)\n",
    "    plt.ylabel('Anzahl von Synsets',fontsize=30)\n",
    "    plt.xlabel(\"Idee Id\",fontsize=30)\n",
    "    length = anteile[-1] + 5\n",
    "    plt.ylim(0,length) #y-achse höhe\n",
    "    ax.set_xticks(range(len(ideen_id)))\n",
    "    ax.set_xticklabels(ideen_id, rotation='vertical')\n",
    "    fig_size = plt.gcf().get_size_inches() #Get current size\n",
    "    sizefactor = 3 #Set a zoom factor\n",
    "    autolabel(bars2, ax)\n",
    "    plt.gcf().set_size_inches(sizefactor * fig_size) # Modify the current size by the factor\n",
    "    plt.show()\n",
    "    \n",
    "def plot_mapping_idee_Hypernym(ideen_hypernymDict,prozent):\n",
    "    fig, ax = plt.subplots()\n",
    "    tupel2 = [(k[0], len(v)) for k, v in ideen_hypernymDict.items()]\n",
    "    tupel2.sort(key = sort_by_keys)\n",
    "    prozent2 = ((tupel2[-1][1] * prozent)/100)\n",
    "    kleiner = [k for k,i in tupel2 if i<=prozent2]\n",
    "    #print(kleiner)\n",
    "    print(\"Others: \", kleiner)\n",
    "    tupel = [(k,v) for k,v in tupel2 if k not in kleiner]\n",
    "    tupel.insert(0,(\"Others\",prozent2))\n",
    "    ideen_id = [i[0] for i in tupel]\n",
    "    anteile  = [i[1] for i in tupel]\n",
    "    anteile.sort()\n",
    "    index = np.arange(len(ideen_id))\n",
    "    bars3 = plt.bar(index, anteile,color=\"green\")\n",
    "    plt.xticks(index,ideen_id,fontsize=20)\n",
    "    plt.title(\"Anzahl von Hypernym pro Idee\",fontsize=30)\n",
    "    plt.ylabel('Anzahl von Hypernyme',fontsize=30)\n",
    "    plt.xlabel(\"Idee Id\",fontsize=30)\n",
    "    length = anteile[-1] + 5\n",
    "    plt.ylim(0,length) #y-achse höhe\n",
    "    ax.set_xticks(range(len(ideen_id)))\n",
    "    ax.set_xticklabels(ideen_id, rotation='vertical')\n",
    "    fig_size = plt.gcf().get_size_inches() #Get current size\n",
    "    sizefactor = 3 #Set a zoom factor\n",
    "    plt.gcf().set_size_inches(sizefactor * fig_size) # Modify the current size by the factor\n",
    "    autolabel(bars3,ax)\n",
    "    plt.show()\n",
    "\n",
    "def plot_occurence_synset(occurence_synsetsDict,prozent):\n",
    "    fig, ax = plt.subplots()\n",
    "    tupel2  = [(k, v) for k, v in occurence_synsetsDict.items()]\n",
    "    tupel2.sort(key = sort_by_keys)\n",
    "    prozent2 = ((tupel2[-1][1] * prozent)/100)\n",
    "    kleiner = [k for k,i in tupel2 if i<=prozent2]\n",
    "    print(\"Others: \", kleiner)\n",
    "    tupel   = [(k,v) for k,v in tupel2 if k not in kleiner]\n",
    "    tupel.insert(0,(\"Others\",prozent2))\n",
    "    synsets = [i[0] for i in tupel]\n",
    "    anteile = [i[1] for i in tupel]\n",
    "    anteile.sort()\n",
    "    index = np.arange(len(synsets))\n",
    "    bar_width = 0.5\n",
    "    bars = plt.bar(index, anteile,bar_width,color=\"green\")\n",
    "    plt.xticks(index, synsets,fontsize=20)\n",
    "    plt.title(\"Anzahl von Occurence eines Synset\",fontsize=30)\n",
    "    plt.ylabel('Occurence',fontsize=30)\n",
    "    plt.xlabel(\"Synsets\",fontsize=30)\n",
    "    length = anteile[-1] + 5\n",
    "    plt.ylim(0,length) #y-achse höhe\n",
    "    ax.set_xticks(range(len(synsets)))\n",
    "    ax.set_xticklabels(synsets, style='oblique',rotation='vertical')\n",
    "    fig_size = plt.gcf().get_size_inches() #Get current size\n",
    "    sizefactor = 3 #Set a zoom factor\n",
    "    autolabel(bars,ax)\n",
    "    plt.gcf().set_size_inches(sizefactor * fig_size) # Modify the current size by the factor\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Abstractionsgrad: \n",
    "def Abstractionsgradfunc(ideen_synsetsDict): \n",
    "    AbstractionsDict = {} #key = (numId,Id) value = distance\n",
    "    for key in ideen_synsetsDict.keys():\n",
    "        AbstractionsDict[key] = 0\n",
    "        synsetsdist = []\n",
    "        for syns in ideen_synsetsDict[key]:\n",
    "            paths = wordnet.synset(syns).hypernym_paths() #all Hypernym extract\n",
    "            distList = [len(i) for i in paths]\n",
    "            dist = sum(distList)/len(paths)         #Distance von einen Synset bis zur root\n",
    "            synsetsdist.append(dist)\n",
    "        AbstractionsDict[key] = sum(synsetsdist)/len(ideen_synsetsDict[key])\n",
    "    return AbstractionsDict\n",
    "\n",
    "def Top_Abstract_and_concret(AbstractionsDict,ideenDict,top):\n",
    "    tupel2 = [(k[0],v) for k, v in AbstractionsDict.items()]\n",
    "    tupel2.sort(key = sort_by_keys)\n",
    "    top_Konkreten    = [nummer for (nummer,v) in AbstractionsDict.items() if (nummer[0],v) in tupel2[-top:]]\n",
    "    top_Abstrackten  = [nummer for (nummer,v) in AbstractionsDict.items() if (nummer[0],v) in tupel2[0:top]]\n",
    "    listTop_KonKret  = [(nummer[0],c) for (nummer,c) in ideenDict.items() if nummer in top_Konkreten]\n",
    "    listTop_Abstrakt = [(nummer[0],c) for (nummer,c) in ideenDict.items() if nummer in top_Abstrackten]\n",
    "    Ideen_ID         = [nummer[0] for nummer in tupel2[0:top]] + [nummer[0] for nummer in tupel2[-top:]]\n",
    "    \n",
    "    tabelle = pd.DataFrame({\n",
    "        'ID von Ideen':pd.Categorical(Ideen_ID),                                 \n",
    "        'Abstraktionsgrad' :pd.Categorical([v for (k,v) in tupel2[0:top]] + [v for (k,v) in tupel2[-top:]]),\n",
    "        'Inhalt' :pd.Categorical([i[1] for i in listTop_Abstrakt] + [i[1] for i in listTop_KonKret]) \n",
    "    })\n",
    "    tabelle.to_excel(\"Abstraktionsgrad.xlsx\")\n",
    "    #print(tabelle)\n",
    "    return listTop_Abstrakt,listTop_KonKret\n",
    "\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# read file\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #data loaded\n",
    "    with open('export200.json', 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "    ideen_list   = json.loads(data)\n",
    "    \n",
    "    #Dictionary build\n",
    "    synsetsList  = get_synsetsList(ideen_list)\n",
    "    hypernymList = get_hypernymDict(synsetsList)\n",
    "    ideenDict    = get_dictionaryIdee(ideen_list)\n",
    "    print(\"Anzahl Synsets\", len(synsetsList.keys()))\n",
    "    print(\"Anzahl Hypernym\", len(hypernymList.keys()))\n",
    "    ideen_synset   = mapping_idee_to_synsets(ideen_list)\n",
    "    ideen_hypernym = mapping_idee_to_hypernym(ideen_synset)\n",
    "    synsets_occurence = occurence_of_synset(ideen_synset)\n",
    "    ideen_synsetList_clearly = ideen_synsetDict_clearly(ideen_synset, synsets_occurence)\n",
    "    synsetList_clearly = synsetDict_clearly(ideen_synsetList_clearly, synsetsList )\n",
    "    hypernymList_clearly = get_hypernymDict(synsetList_clearly)\n",
    "    Abstractionsgrad = Abstractionsgradfunc(ideen_synset)\n",
    "    listTop5_Abstrakt,listTop5_KonKret = Top_Abstract_and_concret(Abstractionsgrad,ideenDict,10)\n",
    "    print(listTop5_Abstrakt)\n",
    "    print(listTop5_KonKret)\n",
    "    print(\"Anzahl Synsets clearly\", len(synsetList_clearly.keys()))\n",
    "    print(\"Anzahl Hypernym clearly\", len(hypernymList_clearly.keys()))\n",
    "    \n",
    "    \n",
    "    #Ploting\n",
    "    plot_balken_hypernym(hypernymList_clearly,2.5,30)\n",
    "    plot_hypernyme_fenster(hypernymList,1,200)\n",
    "    plot_mapping_idee_Synstet(ideen_synset,30)\n",
    "    plot_mapping_idee_Hypernym(ideen_hypernym, 30)\n",
    "    plot_occurence_synset(synsets_occurence,10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Tree\n",
    "    dictionaryTree = analyse(synsetsList)\n",
    "    dictionaryTree_clearly = analyse(synsetList_clearly)\n",
    "    #build_tree(dictionaryTree)\n",
    "    #build_tree(dictionaryTree_clearly)\n",
    "    #build_tree_entity(dictionaryTree)\n",
    "    #build_tree_physical_entity(dictionaryTree)\n",
    "    #build_tree_entity(dictionaryTree_clearly)\n",
    "    #build_tree2(dictionaryTree_clearly)\n",
    "    #add_leaves(dictionaryTree)\n",
    "    ''''print(\"entity list\", (dictionaryTree['entity.n.01']))\n",
    "    print(len(dictionaryTree_clearly['entity.n.01']))\n",
    "    print((dictionaryTree['physical_entity.n.01']))\n",
    "    print((dictionaryTree_clearly['physical_entity.n.01']))\n",
    "    print(\"erste\", (dictionaryTree['measure.n.02']))\n",
    "    print(\"erste\", (dictionaryTree_clearly['measure.n.02']))\n",
    "    print(\"zweite\",(dictionaryTree['communication.n.02']))\n",
    "    print(\"zweite\",(dictionaryTree_clearly['communication.n.02']))\n",
    "    print(\"drei\", (dictionaryTree['attribute.n.02']))\n",
    "    print(\"drei\", (dictionaryTree_clearly['attribute.n.02']))\n",
    "    print(\"Vier\", (dictionaryTree['relation.n.01']))\n",
    "    print(\"Vier\", (dictionaryTree_clearly['relation.n.01']))\n",
    "    print(\"fünf\", (dictionaryTree['group.n.01']))\n",
    "    print(\"fünf\", (dictionaryTree_clearly['group.n.01']))\n",
    "    print(\"abstr_clear\", (dictionaryTree_clearly['psychological_feature.n.01']))\n",
    "    print(\"abstr\", (dictionaryTree['psychological_feature.n.01']))\n",
    "    #print(\"abstr\", (ideen_hypernym['causal_agent.n.01']))\n",
    "    casual_agent = [ideenDict[(i,id1)] for (i,id1) in ideenDict.keys() if id1 in hypernymList['causal_agent.n.01']]  \n",
    "    print(len(casual_agent))'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    #build_part_of_tree(dictionaryTree, \"physical_entity.n.01\")\n",
    "   \n",
    "  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
